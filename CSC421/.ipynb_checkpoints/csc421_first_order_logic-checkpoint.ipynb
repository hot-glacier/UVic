{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSC 421 - Propositional and First-Order Logic \n",
    "\n",
    "### Instructor: Brandon Haworth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook Credit: George Tzanetakis\n",
    "Jupyter Notebooks you encounter during the course were largely developed by Prof. Tzanetakis from a previous iteration of this course. I've since changed/developed them where necessary for my own iterations of CSC 421."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSOCIATED READINGS  \n",
    "The section numbers are based on the 4th edition of the textbook. \n",
    "\n",
    "Chapter 8\n",
    "\n",
    "* All Sections\n",
    "\n",
    "Chapter 9\n",
    "\n",
    "* 9.1, 9.2, 9.3, 9.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First-Order Logic \n",
    "\n",
    "Programming languages (such as C++, Java, or Python) are the largest class of formal languages in common use. Data structures within programs can be used to represent facts (for example a 4x4 array can represent the contents of the Wumpus world). However, they lack a general mechanism for deriving facts from other facts. \n",
    "In propositional logic language is **declarative** so that knowledge is domain-specific but inference is general and domain-independent. \n",
    "In programming languages, there is no easy way to express partial information/knowledge (pit in [2,2] or [3,1])\n",
    "\n",
    "\n",
    "Propositional logic is very verbose when dealing with multiple objects - there is no way to generalize rules for all objects. For example \"Squares adjacent to pits are breezy\" can only be expressed as multiple propositional sentences for every possible square and pit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language, Understanding and the relationship to AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural languages (like English or Greek) are very expressive so perhaps they could be used for representation. However, they are complicated and more geared toward communication rather than representation. For example when we say \"Look\" we don't represent a fact but rather convey information that depends on context. \n",
    "\n",
    "\n",
    "**Sapir-Whorf** hypothesis claims that our understanding of the world is strongly influenced by the language we speak. For example, there are words in different languages that can not be directly translated. An example would be Φιλότιμο. It is a composite word consisting of Φιλία (friendship) and Τιμή (honour) and refers \n",
    "to respecting honour and prioritizing the well-being of others and not yourself. Notice although there is no one-to-one translation I was able to communicate to you the underlying meaning. \n",
    "\n",
    "Do you think verbally (Voice in your head?) or do we use non-verbal representations? \n",
    "\n",
    "\n",
    "## Sidenote II \n",
    "\n",
    "Speakers of the Australian aboriginal language (Guugu Yimithirr) have no words for egocentric directions such as front, back, right, left. Instead, they use absolute directions - for example, \"My north arm is hurting\". They are better at navigation even in a virtual reality environment than English speakers. \n",
    "\n",
    "\n",
    "## Sidenote (WEIRD) III \n",
    "\n",
    " There have been a lot of studies in cognitive science/psychology that assume that our perception or cognitive processes are not dependent on culture. In recent years it has been found that this is not the case. A lot of these studies use the most readily available subjects i.e. undergraduate students at Universities. A common acronym used for such subjects is **WEIRD**. The assumption was that for things like what food or music someone likes culture is extremely important but perception and cognition are more universal.  **WEIRD** represents Western, educated, and from industrialized, rich, and democratic countries. \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " <img src=\"images/weird_illusion.png\" width=\"75%\"/>\n",
    "\n",
    " \n",
    "For the **San** people of the **Kalahari** desert, this is not an illusion although it is clearly an illusion \n",
    "for **WEIRD** subjects. \n",
    "\n",
    "\n",
    "See the classic paper by Joe Henrich: \n",
    "https://www2.psych.ubc.ca/~henrich/pdfs/WeirdPeople.pdf\n",
    "\n",
    "## People addressing this type of gap\n",
    "An article from CBC British Columbia highlighted the work of Ife Adebara, PhD Student in the DL & NLP group at UBC, working on Afrocentric Natural Language Processing.\n",
    "https://www.cbc.ca/news/canada/british-columbia/ai-african-language-1.7104038\n",
    "\n",
    "Check out Ife's work **SERENGETI**\n",
    "> To date, only ~31 out of 2,000 African languages are covered in existing language models. We ameliorate this limitation by developing SERENGETI, a set of massively multilingual language model that covers 517 African languages and language varieties.\n",
    "\n",
    "https://github.com/UBC-NLP/serengeti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First-Order Logic \n",
    "\n",
    "1. **Objects**  (squares, pits, wumpuses) nouns and noun phrases \n",
    "2. **Relationships** (breezy, adjacent to, shoots) verbs, verb phrases, adjectives, adverbs \n",
    "\n",
    "For example \"Squares neighbouring the wumpus are smelly\"\n",
    "\n",
    "* Objects: wumpus, squares \n",
    "* Property: smelly \n",
    "* Relationship: neighbouring "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntax and Semantics for FOL \n",
    "\n",
    "Example domain (5 objects): Richard, John, the left leg of Richard, the left leg of John, and crown \n",
    "\n",
    "Relationships are sets of tuples (explicit enumeration similar to CSP): \n",
    "<Richard, John> \n",
    "<John, Richard> \n",
    "\n",
    "Unary relations or properties: \"person\" property is True of Richard and John \n",
    "\n",
    "<img src=\"images/fol_richard.png\" width=\"75%\"/>\n",
    "\n",
    "\n",
    "## Syntax \n",
    "\n",
    "**Constant symbols** stand for objects \n",
    "**Predicate symbols** stand for relationships \n",
    "**Function symbols** stand for functions \n",
    "\n",
    "Each predicate and function symbol comes with an **arity** that fixes the number of arguments. \n",
    "\n",
    "**Functions** can have multiple arguments but are just a different way of referring to an object. \n",
    "The dog walker of Gemma and Fido refers to a person. \n",
    "Helen walks Gemma and Fido (Gemma and Fido are walked by Helen) -> states that a relationship is true \n",
    "\n",
    "* **Atomic sentences** state facts about objects \n",
    "* **Complex sentences** are formed by using **logical connectives** to construct more complex sentences. \n",
    "* **Quantifiers** express properties of entire collections of objects \n",
    "* **Universal quantifier** $\\forall$ All kings are persons can be written as $\\forall x King(x) \\Rightarrow Person(x)$\n",
    "\n",
    "The symbol $x$ is called a **variable**. Variables are written as lowercase letters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Universal quantification $\\forall$\n",
    "\n",
    "All kings are persons can be written as $\\forall x King(x) \\Rightarrow Person(x)$\n",
    "\n",
    "For all x, if x is a king then x is a person. \n",
    "\n",
    "One way to think about this is as a pattern for generating sentences with specific objects. \n",
    "For example, we can have $x$ be Richard or John or any other object (in our domain the leg of John, the leg of Richard, or the crown). \n",
    "\n",
    "Here are the generated sentences: \n",
    "\n",
    "* Richard is king $\\Rightarrow$ Richard is a person \n",
    "* John is king $\\Rightarrow$ John is a person \n",
    "* Richard's left leg is a king $\\Rightarrow$ Richard's left leg is a person \n",
    "* John's left leg is a king $\\Rightarrow$ John's left leg is a person \n",
    "* The crown is a king $\\Rightarrow$ the crown is a person \n",
    "\n",
    "Note that implication is true whenever the premise is false - regardless of the truth of the conclusion. \n",
    "By using **implication** we end up asserting the conclusion of the rule just for those objects for which the premise is true and saying nothing at all about those objects for which the premise is false. \n",
    "\n",
    "A common mistake is to use conjunction $\\wedge$ instead of implication: $\\forall x King(x) \\wedge Person(x)$\n",
    "This would expand to: \n",
    "* Richard is a king $\\wedge$ Richard is a person. \n",
    "* John is a king $\\wedge$ John is a person. \n",
    "* Richard's left leg is a king $\\wedge$ Richard's left leg is a person. \n",
    "* ... \n",
    "\n",
    "Obviously, this is not what we want. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Existential quantification $\\exists$\n",
    "\n",
    "King John has a crown on his head <br> \n",
    "$\\exists x Crown(x) \\wedge OnHead(x, John)$ \n",
    "\n",
    "The sentence is true in *at least* one sentence when substituting the variable x with specific objects. \n",
    "For example at least one of the following is true: \n",
    "\n",
    "* Richard is a crown $\\wedge$ Rich is on John's head \n",
    "* John is a crown $\\wedge$ John is on Jonh's head \n",
    "* Richard's left leg is crown $\\wedge$ Richard's left leg is on John's head \n",
    "* John's left leg is a crown $\\wedge$ John's left leg is on John's head \n",
    "* The crown is a crown $\\wedge$ the crown is on John's head. \n",
    "\n",
    "For existential quantification, the natural connective to use is $wedge$. \n",
    "Notice that using implication does not work well. For example, consider \n",
    "\n",
    "* $\\exists x Crown(x) \\Rightarrow OnHead(x,John)$ \n",
    "\n",
    "Expands to: \n",
    "* Richard is crown $\\Rightarrow$ Richard is on John's head \n",
    "* John is a crown $\\Rightarrow$ John is on John's head \n",
    "\n",
    "If Richard is not a crown then the first assertion is true and the existential is satisfied \n",
    "which is not what we want. \n",
    "\n",
    "\n",
    "### Equality symbol \n",
    "\n",
    "The equality symbol is used to indicate that two terms refer to the same object. \n",
    "For exampole Father(Bart) = Homer \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Translating English to FOL \n",
    "\n",
    "I strongly advise using parentheses instead of relying on the precedence of operators. \n",
    "Also, notice that there are always several (equivalent) sentences in first-order logic \n",
    "that correspond to a given English sentence. \n",
    "\n",
    "In predicates, a common convention is that the first argument is treated as the subject. For example \n",
    "\"The father of Bart is Homer is written as father(Bart, Homer) rather than father(Homer, Bart). \n",
    "Also, notice the use of equality and inequality in the statements below. \n",
    "\n",
    "\n",
    "Examples: \n",
    "\n",
    "* All students are smart <br> \n",
    "$\\forall x Student(x) \\Rightarrow Smart(x)$\n",
    "* There exists a student <br> \n",
    "$\\exists x Student(x)$\n",
    "* There exists a smart student <br> \n",
    "$\\exists x Student(x) \\wedge Smart(x)$\n",
    "* Every student studies with some student  <br> \n",
    "$\\forall x Student(x) \\Rightarrow \\exists y (Student(y) \\wedge StudiesWith(x,y))$\n",
    "* Every student studies with some other student  \n",
    "$\\forall x Student(x) \\Rightarrow \\exists y (Student(y) \\wedge \\neg (x=y) \\wedge StudiesWith(x,y))$\n",
    "* There is a student who studies with every other student <br> \n",
    "$\\exists x (Student(x) \\wedge \\forall y (Student(y) \\wedge \\neg (x=y) ) \\Rightarrow StudiesWith(y,x)$\n",
    "* George is a student <br> \n",
    "$Student(George)$ \n",
    "* George takes either AI or Data Mining (but not both) <br> \n",
    "$Takes(George, AI) \\Leftrightarrow \\neg \n",
    "Takes(George, Datamining)$\n",
    "* George takes both AI and Data mining <br> \n",
    "$Takes(George, AI) \\wedge Takes(George, Datamining)$\n",
    "* No student studies with George <br>\n",
    "$\\neg \\exists x (Student(x) \\wedge StudiesWith(x, George)$\n",
    "* George has at least one sister <br> \n",
    "$\\exists x SisterOf(x,George)$\n",
    "* George has no sister <br> \n",
    "$\\neg \\exists x SisterOf(x,George)$\n",
    "* George has at most one sister <br> \n",
    "$\\forall x \\forall y (SisterOf(x,George) \\wedge SisterOf(y,George) \\Rightarrow x = y)$\n",
    "* George has exactly one sister <br> \n",
    "$\\exists x (SisterOf(x,George) \\wedge \\forall y (SisterOf(y,George) \\Rightarrow x = y))$\n",
    "* George has at least two sisters <br> \n",
    "$\\exists x \\exists y (SisterOf(x,George) \\wedge (SisterOf(y,George) \\wedge \\neg(x=y))$\n",
    "* Every student takes at least one course <br> \n",
    "$\\forall x (Student(x) \\Rightarrow \\exists y (Course(y) \\wedge Takes(x,y))) $\n",
    "* Only one student failed AI. <br>\n",
    "$\\exists x (Student(x) \\wedge Failed(x,AI) \\wedge \\forall y (Student(y) \\wedge Failed(y,AI) \\Rightarrow x=y))$\n",
    "* No student failed AI, but at least one student failed Data Mining <br> \n",
    "$\\neg \\exists x (Student(x) \\wedge Failed(x,AI)) \\wedge \\exists x (Student (x) \\wedge Failed(x,DataMining))$ \n",
    "* Every student who takes AI also takes Data Mining. <br> \n",
    "$\\forall x (Student(x) \\wedge Takes(x,AI)) \\Rightarrow Takes(x,DataMining)$ \n",
    "* No student can fool all the other students <br> \n",
    "$\\neg \\exists x (Student(x) \\wedge \\forall y (Student(y) \\wedge \\neg (x=y) ⇒ Fools(x,y)))$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kinship Domain \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a slightly more useful example than the King Richard and John example. The kinship domain \n",
    "refers to knowledge about family relationships. \n",
    "\n",
    "An example KB can include things like:\n",
    "\n",
    "* Facts:\n",
    "    * \"Elizabeth is the parent of Charles”\n",
    "    * “Charles is the parent of William”\n",
    "* Rules:\n",
    "    * One’s grandparent is the parent of one’s parent”\n",
    "* Object: people\n",
    "    * Binary predicate: Child, Spouse, Grandparent, Grandchild, Cousin, Pibling (Parent's sibling)\n",
    "* Function: Mother, Father\n",
    "\n",
    "\n",
    "\n",
    "* Parent(Homer,Bart) \n",
    "* Parent and child are inverse relations <br> \n",
    "$\\forall p,c Parent(p,c) \\Leftrightarrow Child(c,p)$ \n",
    "* A grandparent is a parent of one's parent <br> \n",
    "$\\forall g,c GrandParent(g,c) \\Leftrightarrow \\exists p Parent(g,p) \\wedge Parent(p,c)$\n",
    "\n",
    "\n",
    "\n",
    "The cool feature of creating a knowledge base using FOL is that it allows one to enter facts \n",
    "and then create all sorts of complex queries by combining variables and constants in \n",
    "FOL sentences. Relational algebra which is the theory behind database languages such as SQL can be viewed \n",
    "as a subset of FOL.\n",
    "\n",
    "\n",
    "You can read in your textbook about the Electronic Circuits Domain which can be used for verifying properties of circuits. Hardware verification is an important application of theorem-proving systems. \n",
    "\n",
    "\n",
    "\n",
    "### Advanced \n",
    "\n",
    "You can read more about these connections starting from the Wikipedia entry on Datalog. \n",
    "https://en.wikipedia.org/wiki/Datalog\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference in Propositional Logic \n",
    "\n",
    "Conjunctive Normal form (CNF) is a simplified and equivalent way of writing sentences \n",
    "in a canonical way with fewer symbols. It makes the implementation of inference simpler \n",
    "but it is not as readable/understandable for humans. \n",
    "\n",
    "Every sentence of propositional logic is logically equivalent to a conjunction of clauses. \n",
    "The conversion to CNF can be performed as follows: \n",
    "\n",
    "1. Eliminate biconditionals \n",
    "2. Eliminate implications \n",
    "3. Move $\\neg$ inwards by repeated application of double negation elimination and DeMorgan \n",
    "4. Apply distributivity law \n",
    "\n",
    "Now we have our sentence as a conjunction of clauses and it is easier to perform inference using \n",
    "resolution. \n",
    "\n",
    "\n",
    "You can read about resolution in the textbook. It basically consists of repeated application \n",
    "of rules that simplify the CNF sentences until the query can be proven (if that is possible). \n",
    "Resolution is a complete and sound inference procedure for Propositional Logic. \n",
    "\n",
    "Definite clauses and Horn Clauses are restricted forms of Propositional Logic. They are still \n",
    "quite expressive and lots of problems can be solved with them. If Horn Clauses are used inference \n",
    "using theorem proving can be performed much more efficiently. One can start from the KB and keep \n",
    "adding clauses based on the existing sentences until eventually the query is generated (forward chaining) \n",
    "or one can start from the goal and work \"backwards\" using the KB (backward chaining). In addition to \n",
    "being more efficient forward and backward chaining produce \"proofs\" (i.e sequences of transformation steps) \n",
    "that are easier to understand and interpret by humans. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference in First-Order Logic \n",
    "\n",
    "\n",
    "It is possible to automatically convert any FOL KB to a propositional one by converting all sentences with variables to multiple sentences where the variables are substituted with objects. Once this process is completed one can run the inference algorithms we learned in Propositional Logic to answer queries. This approach works \n",
    "but it is not efficient. \n",
    "\n",
    "It is also possible to extend both resolution to FOL as well as forward/backward chaining if the FOL knowledge base consists of Horn clauses. Prolog is programming language based on Horn clauses. \n",
    "\n",
    "### Advanced \n",
    "\n",
    "Read chapter 9 of the textbook about various inference procedures for FOL and chapter 10 about \n",
    "how FOL can be used to model different aspects of the world. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
